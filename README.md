# **ğŸ‘ AI-Powered Sign Language Recognition**  
**Enhancing accessibility with AI and embedded systems**  

### **ğŸš€ Project Overview**  
This project leverages **computer vision, deep learning, and embedded hardware** to recognize **American Sign Language (ASL) hand gestures** in real time. The goal is to bridge communication gaps by translating ASL gestures into **text and speech**, making conversations more accessible for the **Deaf and Hard-of-Hearing (DHH) community**.  

The initial phase focuses on **AI-powered sign recognition using OpenCV and TensorFlow**, while the future roadmap includes **hardware integration with Arduino and flex sensors** to build a **wearable assistive device**.

---

## **ğŸ”¹ Features**  
âœ… **Computer Vision-Based Sign Detection** â€“ AI recognizes ASL hand gestures from a webcam.  
âœ… **Deep Learning for Gesture Recognition** â€“ Trained with a pre-existing ASL dataset for accuracy.  
âœ… **Real-Time Translation** â€“ Converts sign language gestures into **on-screen text** or **speech output**.  
âœ… **Assistive Technology Focus** â€“ Designed to **increase accessibility** for non-verbal communication.  
âœ… **Future Hardware Integration** â€“ Next phase includes **Arduino + flex sensors** for a wearable glove.  

---

## **ğŸ› ï¸ Technologies Used**  
### **AI & Software**  
- **Python** â€“ Primary programming language  
- **TensorFlow / Keras** â€“ Model training and prediction  
- **OpenCV** â€“ Real-time hand tracking  
- **MediaPipe** â€“ Hand landmark detection  
- **Numpy & Pandas** â€“ Data preprocessing  

### **Embedded Systems & Hardware (Future Roadmap)**  
- **Arduino Uno / ESP32** â€“ Microcontroller for gesture sensing  
- **Flex Sensors** â€“ Detect finger movement in gloves  
- **Bluetooth Module (HC-05)** â€“ Wireless communication between gloves and the AI model  
- **OLED Display / Speaker** â€“ Output device for displaying or speaking detected gestures  

---

## **ğŸ› ï¸ Project Structure (To Be Updated)**  
```
/sign-language-ai
â”‚â”€â”€ models/                  # Trained AI models  
â”‚â”€â”€ datasets/                # ASL dataset used for training  
â”‚â”€â”€ src/                     # Python scripts for detection & classification  
â”‚â”€â”€ hardware/                # Arduino code for future integration  
â”‚â”€â”€ notebooks/               # Jupyter notebooks for experiments  
â”‚â”€â”€ README.md                # Project documentation  
â”‚â”€â”€ requirements.txt         # Dependencies  
```

---

## **ğŸš§ Project Status**  
ğŸ“Œ **Current Phase:**  
âœ… Training **AI model for sign recognition** (using OpenCV + TensorFlow).  
âœ… Developing **real-time webcam detection** for ASL gestures.  

ğŸ“Œ **Next Steps:**  
ğŸ”¹ Improve model accuracy with **data augmentation and fine-tuning**.  
ğŸ”¹ Integrate **text-to-speech (TTS)** for voice output.  
ğŸ”¹ Prototype **Arduino-based glove with flex sensors** for hardware integration.  

---

## **ğŸ“¸ Demo Screenshots (To Be Added)**  
ğŸ”¹ Hand detection example  
ğŸ”¹ ASL gesture classification output  
ğŸ”¹ Future hardware prototype preview  

---

## **ğŸ’¡ Why This Project?**  
ğŸŒ **Inclusion & Accessibility:** Sign language is a vital means of communication for the Deaf community, but **many people donâ€™t understand ASL**. This project aims to **bridge that gap using AI and assistive tech**.  

ğŸ”¬ **AI & Embedded Systems Integration:** Combining **machine learning with hardware** opens new doors for **real-world impact in accessibility technologies**.  

ğŸ’» **Open-Source Contribution:** The goal is to make this **an open-source project** so that others can contribute and improve the model.  

---

## **ğŸ“Œ How to Run the Project (Coming Soon)**  
1. **Clone the repository**  
   ```bash
   git clone https://github.com/ashleyprado/sign-language-ai
   cd sign-language-ai
   ```
2. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   ```
3. **Run real-time ASL detection script**  
   ```bash
   python src/detect_signs.py
   ```

---

## **ğŸ¤ Contributing**  
Interested in contributing to this project? Feel free to fork the repo, submit a pull request, or reach out to collaborate!  

---

## **ğŸ“¬ Contact & Updates**  
ğŸ‘©â€ğŸ’» **Project Lead:** Ashley Prado  
ğŸ“© **Email:** ashleypradoceleste@gmail.com  
ğŸ”— **GitHub Repo:** [GitHub Link] (Replace this with the actual repo link)  
ğŸ“Œ **WeCode Harvard 2025 Presentation**  

---

## **ğŸŒŸ Future Vision**  
This project is more than just a software modelâ€”itâ€™s a **step toward making sign language translation more accessible through AI and wearable technology.** By combining **deep learning and embedded systems**, this solution has the potential to evolve into **a real-time sign language translator for everyday use.**  
\
